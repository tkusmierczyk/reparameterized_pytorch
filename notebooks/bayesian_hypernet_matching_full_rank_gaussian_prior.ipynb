{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJcMJWZDBy2h"
      },
      "source": [
        "# Matching q(z), z:=v/|v|*g, g~NF to p=Normal by minimizing KL(q|p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJd1yRdoJgA7",
        "outputId": "ac8f8121-db81-47a0-f47e-eb001f0b38c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "PkWZ_bKBJYeT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from torch.distributions import MultivariateNormal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1.13.0+cu117'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiEnOgwGJaEn",
        "outputId": "c8936bc9-58b4-4ecf-fcea-88d08592c3c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using CPU\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "    ENV = torch.cuda\n",
        "    print(\"Using GPU\")\n",
        "else:\n",
        "    torch.set_default_tensor_type('torch.FloatTensor')\n",
        "    ENV = torch\n",
        "    print(\"Using CPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "JVdgdm7Cd5UI"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = (5, 5) # Width and height"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"../\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "from reparametrized import sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sanity check our implementation of weight_norm  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import nn, _weight_norm\n",
        "from torch.nn.utils import weight_norm\n",
        "from reparametrized.sampling.bayesian_hypernets import _weight_norm_our"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One sample:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 5]) torch.Size([3, 1]) torch.Size([3, 5])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(tensor(0., grad_fn=<MaxBackward1>),\n",
              " tensor(1.4901e-08, grad_fn=<MaxBackward1>))"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# m = weight_norm(nn.Conv3d(11, 5, (7,3,2)), name=\"weight\")\n",
        "m = weight_norm(nn.Linear(5, 3), name=\"weight\")\n",
        "\n",
        "v = m.weight_v\n",
        "g = m.weight_g\n",
        "print(m.weight.shape, g.shape, v.shape)\n",
        "\n",
        "(_weight_norm(v,g,dim=0)-m.weight).max(), (_weight_norm_our(v,g,dim=0)-m.weight).max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Multiple samples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(4.4703e-08, grad_fn=<MaxBackward1>)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ms, vs, gs = [], [], []\n",
        "for _ in range(17):\n",
        "    m = weight_norm(nn.Linear(11, 5), name=\"weight\")\n",
        "    # m = weight_norm(nn.Conv3d(11, 5, (7,3,2)), name=\"weight\")\n",
        "    \n",
        "    v, g = m.weight_v,  m.weight_g\n",
        "    \n",
        "    ms.append(m.weight)\n",
        "    vs.append(v)\n",
        "    gs.append(g)\n",
        "ms = torch.stack(ms)\n",
        "vs = torch.stack(vs)\n",
        "gs = torch.stack(gs)\n",
        "\n",
        "(_weight_norm_our(vs, gs, dim=1)-ms).max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dimensionality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "18IvegmjJYea"
      },
      "outputs": [],
      "source": [
        "parameter_shape = (3, 2)  # for Bayesian hypernets parameters dimensionality must be >=2D, and first dim>1\n",
        "\n",
        "# some samplers initialize with this value; others just match its shape\n",
        "parameter_init_value = torch.randn(torch.Size(parameter_shape))  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create target p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Some full-rank Gaussian:\n",
        "# t = torch.tensor(range(parameter_shape[0]))*3.\n",
        "# cov = t[None,:]*t[:,None]+300*torch.eye(parameter_shape[0])\n",
        "# for i, j in [(1, 3), (5, 3)]:\n",
        "#     cov[i, j] = -cov[i, j]\n",
        "#     cov[j, i] = -cov[j, i]\n",
        "# loc = torch.tensor(range(parameter_shape[0], 0, -1))*2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Factorized Gaussian:\n",
        "loc = torch.zeros(parameter_init_value.numel())\n",
        "cov = torch.eye(parameter_init_value.numel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([0., 0., 0., 0., 0., 0.]),\n",
              " tensor([[1., 0., 0., 0., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 1.]]))"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# target\n",
        "loc, cov"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "p = MultivariateNormal(loc=loc, covariance_matrix=cov)\n",
        "\n",
        "def calc_p_nll(samples):\n",
        "    samples = samples.flatten(start_dim=1)\n",
        "    return -p.log_prob(samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "g_shape=torch.Size([3, 1]) v_shape=torch.Size([3, 2])\n"
          ]
        }
      ],
      "source": [
        "sampler, variational_params, aux_objs = sampling.create_bayesian_hypernet_sampler(parameter_init_value, \n",
        "                                                                     realnvp_m=8,  # change default parameters!\n",
        "                                                                     realnvp_num_layers=16,\n",
        "                                                                     rezero_trick=False,\n",
        "                                                                     only_flow_nll=False,\n",
        "                                                                     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'t.0.0.weight': torch.Size([8, 2]),\n",
              " 't.0.0.bias': torch.Size([8]),\n",
              " 't.0.2.weight': torch.Size([8, 8]),\n",
              " 't.0.2.bias': torch.Size([8]),\n",
              " 't.0.4.weight': torch.Size([1, 8]),\n",
              " 't.0.4.bias': torch.Size([1]),\n",
              " 't.1.0.weight': torch.Size([8, 2]),\n",
              " 't.1.0.bias': torch.Size([8]),\n",
              " 't.1.2.weight': torch.Size([8, 8]),\n",
              " 't.1.2.bias': torch.Size([8]),\n",
              " 't.1.4.weight': torch.Size([1, 8]),\n",
              " 't.1.4.bias': torch.Size([1]),\n",
              " 't.2.0.weight': torch.Size([8, 2]),\n",
              " 't.2.0.bias': torch.Size([8]),\n",
              " 't.2.2.weight': torch.Size([8, 8]),\n",
              " 't.2.2.bias': torch.Size([8]),\n",
              " 't.2.4.weight': torch.Size([1, 8]),\n",
              " 't.2.4.bias': torch.Size([1]),\n",
              " 't.3.0.weight': torch.Size([8, 2]),\n",
              " 't.3.0.bias': torch.Size([8]),\n",
              " 't.3.2.weight': torch.Size([8, 8]),\n",
              " 't.3.2.bias': torch.Size([8]),\n",
              " 't.3.4.weight': torch.Size([1, 8]),\n",
              " 't.3.4.bias': torch.Size([1]),\n",
              " 't.4.0.weight': torch.Size([8, 2]),\n",
              " 't.4.0.bias': torch.Size([8]),\n",
              " 't.4.2.weight': torch.Size([8, 8]),\n",
              " 't.4.2.bias': torch.Size([8]),\n",
              " 't.4.4.weight': torch.Size([1, 8]),\n",
              " 't.4.4.bias': torch.Size([1]),\n",
              " 't.5.0.weight': torch.Size([8, 2]),\n",
              " 't.5.0.bias': torch.Size([8]),\n",
              " 't.5.2.weight': torch.Size([8, 8]),\n",
              " 't.5.2.bias': torch.Size([8]),\n",
              " 't.5.4.weight': torch.Size([1, 8]),\n",
              " 't.5.4.bias': torch.Size([1]),\n",
              " 't.6.0.weight': torch.Size([8, 2]),\n",
              " 't.6.0.bias': torch.Size([8]),\n",
              " 't.6.2.weight': torch.Size([8, 8]),\n",
              " 't.6.2.bias': torch.Size([8]),\n",
              " 't.6.4.weight': torch.Size([1, 8]),\n",
              " 't.6.4.bias': torch.Size([1]),\n",
              " 't.7.0.weight': torch.Size([8, 2]),\n",
              " 't.7.0.bias': torch.Size([8]),\n",
              " 't.7.2.weight': torch.Size([8, 8]),\n",
              " 't.7.2.bias': torch.Size([8]),\n",
              " 't.7.4.weight': torch.Size([1, 8]),\n",
              " 't.7.4.bias': torch.Size([1]),\n",
              " 't.8.0.weight': torch.Size([8, 2]),\n",
              " 't.8.0.bias': torch.Size([8]),\n",
              " 't.8.2.weight': torch.Size([8, 8]),\n",
              " 't.8.2.bias': torch.Size([8]),\n",
              " 't.8.4.weight': torch.Size([1, 8]),\n",
              " 't.8.4.bias': torch.Size([1]),\n",
              " 't.9.0.weight': torch.Size([8, 2]),\n",
              " 't.9.0.bias': torch.Size([8]),\n",
              " 't.9.2.weight': torch.Size([8, 8]),\n",
              " 't.9.2.bias': torch.Size([8]),\n",
              " 't.9.4.weight': torch.Size([1, 8]),\n",
              " 't.9.4.bias': torch.Size([1]),\n",
              " 't.10.0.weight': torch.Size([8, 2]),\n",
              " 't.10.0.bias': torch.Size([8]),\n",
              " 't.10.2.weight': torch.Size([8, 8]),\n",
              " 't.10.2.bias': torch.Size([8]),\n",
              " 't.10.4.weight': torch.Size([1, 8]),\n",
              " 't.10.4.bias': torch.Size([1]),\n",
              " 't.11.0.weight': torch.Size([8, 2]),\n",
              " 't.11.0.bias': torch.Size([8]),\n",
              " 't.11.2.weight': torch.Size([8, 8]),\n",
              " 't.11.2.bias': torch.Size([8]),\n",
              " 't.11.4.weight': torch.Size([1, 8]),\n",
              " 't.11.4.bias': torch.Size([1]),\n",
              " 't.12.0.weight': torch.Size([8, 2]),\n",
              " 't.12.0.bias': torch.Size([8]),\n",
              " 't.12.2.weight': torch.Size([8, 8]),\n",
              " 't.12.2.bias': torch.Size([8]),\n",
              " 't.12.4.weight': torch.Size([1, 8]),\n",
              " 't.12.4.bias': torch.Size([1]),\n",
              " 't.13.0.weight': torch.Size([8, 2]),\n",
              " 't.13.0.bias': torch.Size([8]),\n",
              " 't.13.2.weight': torch.Size([8, 8]),\n",
              " 't.13.2.bias': torch.Size([8]),\n",
              " 't.13.4.weight': torch.Size([1, 8]),\n",
              " 't.13.4.bias': torch.Size([1]),\n",
              " 't.14.0.weight': torch.Size([8, 2]),\n",
              " 't.14.0.bias': torch.Size([8]),\n",
              " 't.14.2.weight': torch.Size([8, 8]),\n",
              " 't.14.2.bias': torch.Size([8]),\n",
              " 't.14.4.weight': torch.Size([1, 8]),\n",
              " 't.14.4.bias': torch.Size([1]),\n",
              " 't.15.0.weight': torch.Size([8, 2]),\n",
              " 't.15.0.bias': torch.Size([8]),\n",
              " 't.15.2.weight': torch.Size([8, 8]),\n",
              " 't.15.2.bias': torch.Size([8]),\n",
              " 't.15.4.weight': torch.Size([1, 8]),\n",
              " 't.15.4.bias': torch.Size([1]),\n",
              " 's.0.0.weight': torch.Size([8, 2]),\n",
              " 's.0.0.bias': torch.Size([8]),\n",
              " 's.0.2.weight': torch.Size([8, 8]),\n",
              " 's.0.2.bias': torch.Size([8]),\n",
              " 's.0.4.weight': torch.Size([1, 8]),\n",
              " 's.0.4.bias': torch.Size([1]),\n",
              " 's.1.0.weight': torch.Size([8, 2]),\n",
              " 's.1.0.bias': torch.Size([8]),\n",
              " 's.1.2.weight': torch.Size([8, 8]),\n",
              " 's.1.2.bias': torch.Size([8]),\n",
              " 's.1.4.weight': torch.Size([1, 8]),\n",
              " 's.1.4.bias': torch.Size([1]),\n",
              " 's.2.0.weight': torch.Size([8, 2]),\n",
              " 's.2.0.bias': torch.Size([8]),\n",
              " 's.2.2.weight': torch.Size([8, 8]),\n",
              " 's.2.2.bias': torch.Size([8]),\n",
              " 's.2.4.weight': torch.Size([1, 8]),\n",
              " 's.2.4.bias': torch.Size([1]),\n",
              " 's.3.0.weight': torch.Size([8, 2]),\n",
              " 's.3.0.bias': torch.Size([8]),\n",
              " 's.3.2.weight': torch.Size([8, 8]),\n",
              " 's.3.2.bias': torch.Size([8]),\n",
              " 's.3.4.weight': torch.Size([1, 8]),\n",
              " 's.3.4.bias': torch.Size([1]),\n",
              " 's.4.0.weight': torch.Size([8, 2]),\n",
              " 's.4.0.bias': torch.Size([8]),\n",
              " 's.4.2.weight': torch.Size([8, 8]),\n",
              " 's.4.2.bias': torch.Size([8]),\n",
              " 's.4.4.weight': torch.Size([1, 8]),\n",
              " 's.4.4.bias': torch.Size([1]),\n",
              " 's.5.0.weight': torch.Size([8, 2]),\n",
              " 's.5.0.bias': torch.Size([8]),\n",
              " 's.5.2.weight': torch.Size([8, 8]),\n",
              " 's.5.2.bias': torch.Size([8]),\n",
              " 's.5.4.weight': torch.Size([1, 8]),\n",
              " 's.5.4.bias': torch.Size([1]),\n",
              " 's.6.0.weight': torch.Size([8, 2]),\n",
              " 's.6.0.bias': torch.Size([8]),\n",
              " 's.6.2.weight': torch.Size([8, 8]),\n",
              " 's.6.2.bias': torch.Size([8]),\n",
              " 's.6.4.weight': torch.Size([1, 8]),\n",
              " 's.6.4.bias': torch.Size([1]),\n",
              " 's.7.0.weight': torch.Size([8, 2]),\n",
              " 's.7.0.bias': torch.Size([8]),\n",
              " 's.7.2.weight': torch.Size([8, 8]),\n",
              " 's.7.2.bias': torch.Size([8]),\n",
              " 's.7.4.weight': torch.Size([1, 8]),\n",
              " 's.7.4.bias': torch.Size([1]),\n",
              " 's.8.0.weight': torch.Size([8, 2]),\n",
              " 's.8.0.bias': torch.Size([8]),\n",
              " 's.8.2.weight': torch.Size([8, 8]),\n",
              " 's.8.2.bias': torch.Size([8]),\n",
              " 's.8.4.weight': torch.Size([1, 8]),\n",
              " 's.8.4.bias': torch.Size([1]),\n",
              " 's.9.0.weight': torch.Size([8, 2]),\n",
              " 's.9.0.bias': torch.Size([8]),\n",
              " 's.9.2.weight': torch.Size([8, 8]),\n",
              " 's.9.2.bias': torch.Size([8]),\n",
              " 's.9.4.weight': torch.Size([1, 8]),\n",
              " 's.9.4.bias': torch.Size([1]),\n",
              " 's.10.0.weight': torch.Size([8, 2]),\n",
              " 's.10.0.bias': torch.Size([8]),\n",
              " 's.10.2.weight': torch.Size([8, 8]),\n",
              " 's.10.2.bias': torch.Size([8]),\n",
              " 's.10.4.weight': torch.Size([1, 8]),\n",
              " 's.10.4.bias': torch.Size([1]),\n",
              " 's.11.0.weight': torch.Size([8, 2]),\n",
              " 's.11.0.bias': torch.Size([8]),\n",
              " 's.11.2.weight': torch.Size([8, 8]),\n",
              " 's.11.2.bias': torch.Size([8]),\n",
              " 's.11.4.weight': torch.Size([1, 8]),\n",
              " 's.11.4.bias': torch.Size([1]),\n",
              " 's.12.0.weight': torch.Size([8, 2]),\n",
              " 's.12.0.bias': torch.Size([8]),\n",
              " 's.12.2.weight': torch.Size([8, 8]),\n",
              " 's.12.2.bias': torch.Size([8]),\n",
              " 's.12.4.weight': torch.Size([1, 8]),\n",
              " 's.12.4.bias': torch.Size([1]),\n",
              " 's.13.0.weight': torch.Size([8, 2]),\n",
              " 's.13.0.bias': torch.Size([8]),\n",
              " 's.13.2.weight': torch.Size([8, 8]),\n",
              " 's.13.2.bias': torch.Size([8]),\n",
              " 's.13.4.weight': torch.Size([1, 8]),\n",
              " 's.13.4.bias': torch.Size([1]),\n",
              " 's.14.0.weight': torch.Size([8, 2]),\n",
              " 's.14.0.bias': torch.Size([8]),\n",
              " 's.14.2.weight': torch.Size([8, 8]),\n",
              " 's.14.2.bias': torch.Size([8]),\n",
              " 's.14.4.weight': torch.Size([1, 8]),\n",
              " 's.14.4.bias': torch.Size([1]),\n",
              " 's.15.0.weight': torch.Size([8, 2]),\n",
              " 's.15.0.bias': torch.Size([8]),\n",
              " 's.15.2.weight': torch.Size([8, 8]),\n",
              " 's.15.2.bias': torch.Size([8]),\n",
              " 's.15.4.weight': torch.Size([1, 8]),\n",
              " 's.15.4.bias': torch.Size([1]),\n",
              " 'v': torch.Size([3, 2])}"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Preview variational parameters:\n",
        "{n: p.shape for n, p in variational_params.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preview before optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([10240, 3, 2]), torch.Size([10240]))"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "samples, nlls = sampler(n_samples=10240)\n",
        "samples.shape, nlls.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 0.6833, -0.2525],\n",
              "         [-0.0042,  0.0017],\n",
              "         [ 0.0074, -0.0144]], grad_fn=<MeanBackward1>),\n",
              " tensor([[0.3194, 0.0436],\n",
              "         [0.8496, 0.1381],\n",
              "         [0.1248, 0.4722]], grad_fn=<PowBackward0>),\n",
              " tensor([[ 0.3000, -0.1000,  0.0000, -0.0000, -0.0000,  0.1000],\n",
              "         [-0.1000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000],\n",
              "         [ 0.0000, -0.0000,  0.8000, -0.3000, -0.0000,  0.0000],\n",
              "         [-0.0000,  0.0000, -0.3000,  0.1000,  0.0000, -0.0000],\n",
              "         [-0.0000,  0.0000, -0.0000,  0.0000,  0.1000, -0.2000],\n",
              "         [ 0.1000, -0.0000,  0.0000, -0.0000, -0.2000,  0.5000]],\n",
              "        grad_fn=<RoundBackward1>))"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Means, variances, covariance matrix:\n",
        "samples.mean(0), samples.std(0)**2, torch.cov(samples.flatten(start_dim=1).T).round(decimals=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(samples[:,0].cpu().detach().numpy(), bins=30);\n",
        "plt.title(\"Dim=0 marginal distribution\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.6607, -0.2441],\n",
              "        [-2.2600,  0.9112],\n",
              "        [ 0.6506, -1.2655]], requires_grad=True)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "variational_params[\"v\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdEt2uU1g4qM"
      },
      "source": [
        "## Optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "Gc6q2sg2JYeg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=0: loss= 3.04\n",
            "epoch=10: loss= 2.04\n",
            "epoch=20: loss= 1.43\n",
            "epoch=30: loss= 1.24\n",
            "epoch=40: loss= 1.08\n",
            "epoch=50: loss= 1.02\n",
            "epoch=60: loss= 0.92\n",
            "epoch=70: loss= 0.85\n",
            "epoch=80: loss= 0.80\n",
            "epoch=90: loss= 0.76\n",
            "epoch=500: loss= 0.32\n",
            "epoch=1000: loss= 0.21\n",
            "epoch=1500: loss= 0.24\n",
            "epoch=2000: loss= 0.21\n",
            "epoch=2500: loss= 0.21\n"
          ]
        }
      ],
      "source": [
        "optimized_parameters = variational_params.values()\n",
        "optimizer = torch.optim.Adam(optimized_parameters, lr=0.001) \n",
        "n_epochs = 3000\n",
        "n_posterior_samples = 10\n",
        "\n",
        "for e in range(n_epochs):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    samples, q_nlls = sampler(n_samples=n_posterior_samples)\n",
        "    p_nlls = calc_p_nll(samples)\n",
        "    KLD = p_nlls-q_nlls\n",
        "\n",
        "    loss_vi = KLD.mean()\n",
        "    loss_vi.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (e<100 and e%10==0) or e%500==0:\n",
        "        samples, q_nlls = sampler(n_samples=10240)  # let use  more samples to better estimate reported KLD\n",
        "        p_nlls = calc_p_nll(samples)\n",
        "        KLD = p_nlls-q_nlls\n",
        "\n",
        "        print(f\"epoch={e}: loss={KLD.mean(): .2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preview after optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "um_HOFQK-lEz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[-0.0600,  0.0600],\n",
              "         [ 0.0010, -0.0010],\n",
              "         [-0.1233,  0.1233]], grad_fn=<MeanBackward1>),\n",
              " tensor([[0.9144, 0.9144],\n",
              "         [0.5022, 0.5022],\n",
              "         [1.0119, 1.0119]], grad_fn=<PowBackward0>),\n",
              " tensor([[ 0.9100, -0.9100, -0.0400,  0.0400, -0.0100,  0.0100],\n",
              "         [-0.9100,  0.9100,  0.0400, -0.0400,  0.0100, -0.0100],\n",
              "         [-0.0400,  0.0400,  0.5000, -0.5000,  0.0100, -0.0100],\n",
              "         [ 0.0400, -0.0400, -0.5000,  0.5000, -0.0100,  0.0100],\n",
              "         [-0.0100,  0.0100,  0.0100, -0.0100,  1.0100, -1.0100],\n",
              "         [ 0.0100, -0.0100, -0.0100,  0.0100, -1.0100,  1.0100]],\n",
              "        grad_fn=<RoundBackward1>))"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "samples, nlls = sampler(n_samples=102400)\n",
        "\n",
        "# Means, variances, covariance matrix:\n",
        "samples.mean(0), samples.std(0)**2, torch.cov(samples.flatten(start_dim=1).T).round(decimals=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([0., 0., 0., 0., 0., 0.]),\n",
              " tensor([[1., 0., 0., 0., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 1.]]))"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# target:\n",
        "loc, cov "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "samples, nlls = sampler(n_samples=10240)\n",
        "plt.hist(samples[:, 0].cpu().detach().numpy(), bins=30);\n",
        "plt.title(\"Dim=0 marginal distribution\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.4247, -0.4247],\n",
              "        [-1.5015,  1.5015],\n",
              "        [ 0.9296, -0.9296]], requires_grad=True)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "variational_params[\"v\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Note, the block-diagonal structure in the covariance matrix for the learnt distribution and the symmetry in learnt v. These arise from using the common NF for all inputs to a layer. In particular, here we learn distribution for a parameter (matrix) of size 3x2, i.e., the layer has 3 outputs and 2 outputs.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "-C2DLYqynn54"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.5 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "72dff520818572b45c401a256658ee25fa99b55260abeb0336ef1b1e43b37267"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
