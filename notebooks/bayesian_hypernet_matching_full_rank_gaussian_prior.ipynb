{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJcMJWZDBy2h"
      },
      "source": [
        "# Matching q(z), z:=v/|v|*g, g~NF to p=Normal by minimizing KL(q|p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJd1yRdoJgA7",
        "outputId": "ac8f8121-db81-47a0-f47e-eb001f0b38c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "PkWZ_bKBJYeT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from torch.distributions import MultivariateNormal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1.12.1'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiEnOgwGJaEn",
        "outputId": "c8936bc9-58b4-4ecf-fcea-88d08592c3c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using CPU\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "    ENV = torch.cuda\n",
        "    print(\"Using GPU\")\n",
        "else:\n",
        "    torch.set_default_tensor_type('torch.FloatTensor')\n",
        "    ENV = torch\n",
        "    print(\"Using CPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "JVdgdm7Cd5UI"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = (5, 5) # Width and height"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"../\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "from reparametrized import sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sanity check our implementation of weight_norm  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import nn, _weight_norm\n",
        "from torch.nn.utils import weight_norm\n",
        "from reparametrized.sampling.bayesian_hypernets import _weight_norm_our"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One sample:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 11]) torch.Size([5, 1]) torch.Size([5, 11])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(tensor(0., grad_fn=<MaxBackward1>),\n",
              " tensor(2.9802e-08, grad_fn=<MaxBackward1>))"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# m = weight_norm(nn.Conv3d(11, 5, (7,3,2)), name=\"weight\")\n",
        "m = weight_norm(nn.Linear(11, 5), name=\"weight\")\n",
        "\n",
        "v = m.weight_v\n",
        "g = m.weight_g\n",
        "print(m.weight.shape, g.shape, v.shape)\n",
        "\n",
        "(_weight_norm(v,g,dim=0)-m.weight).max(), (_weight_norm_our(v,g,dim=0)-m.weight).max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Multiple samples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(4.4703e-08, grad_fn=<MaxBackward1>)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ms, vs, gs = [], [], []\n",
        "for _ in range(17):\n",
        "    m = weight_norm(nn.Linear(11, 5), name=\"weight\")\n",
        "    # m = weight_norm(nn.Conv3d(11, 5, (7,3,2)), name=\"weight\")\n",
        "    \n",
        "    v, g = m.weight_v,  m.weight_g\n",
        "    \n",
        "    ms.append(m.weight)\n",
        "    vs.append(v)\n",
        "    gs.append(g)\n",
        "ms = torch.stack(ms)\n",
        "vs = torch.stack(vs)\n",
        "gs = torch.stack(gs)\n",
        "\n",
        "(_weight_norm_our(vs, gs, dim=1)-ms).max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dimensionality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "18IvegmjJYea"
      },
      "outputs": [],
      "source": [
        "parameter_shape = (2, 3)  # for Bayesian hypernets parameters dimensionality must be >=2D\n",
        "\n",
        "# some samplers initialize with this value; others just match its shape\n",
        "parameter_init_value = torch.randn(torch.Size(parameter_shape))  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create target p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Some full-rank Gaussian:\n",
        "# t = torch.tensor(range(parameter_shape[0]))*3.\n",
        "# cov = t[None,:]*t[:,None]+300*torch.eye(parameter_shape[0])\n",
        "# for i, j in [(1, 3), (5, 3)]:\n",
        "#     cov[i, j] = -cov[i, j]\n",
        "#     cov[j, i] = -cov[j, i]\n",
        "# loc = torch.tensor(range(parameter_shape[0], 0, -1))*2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Factorized Gaussian:\n",
        "loc = torch.zeros(parameter_init_value.numel())\n",
        "cov = torch.eye(parameter_init_value.numel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([0., 0., 0., 0., 0., 0.]),\n",
              " tensor([[1., 0., 0., 0., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 1.]]))"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# target\n",
        "loc, cov"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "p = MultivariateNormal(loc=loc, covariance_matrix=cov)\n",
        "\n",
        "def calc_p_nll(samples):\n",
        "    samples = samples.flatten(start_dim=1)\n",
        "    return -p.log_prob(samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "sampler, variational_params, aux_objs = sampling.create_bayesian_hypernet_sampler(parameter_init_value, \n",
        "                                                                     realnvp_m=8,  # change default parameters!\n",
        "                                                                     realnvp_num_layers=16,\n",
        "                                                                     rezero_trick=True,\n",
        "                                                                     only_flow_nll=False,\n",
        "                                                                     )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'alpha': torch.Size([16]),\n",
              " 'beta': torch.Size([16]),\n",
              " 't.0.0.weight': torch.Size([8, 1]),\n",
              " 't.0.0.bias': torch.Size([8]),\n",
              " 't.0.2.weight': torch.Size([8, 8]),\n",
              " 't.0.2.bias': torch.Size([8]),\n",
              " 't.0.4.weight': torch.Size([1, 8]),\n",
              " 't.0.4.bias': torch.Size([1]),\n",
              " 't.1.0.weight': torch.Size([8, 1]),\n",
              " 't.1.0.bias': torch.Size([8]),\n",
              " 't.1.2.weight': torch.Size([8, 8]),\n",
              " 't.1.2.bias': torch.Size([8]),\n",
              " 't.1.4.weight': torch.Size([1, 8]),\n",
              " 't.1.4.bias': torch.Size([1]),\n",
              " 't.2.0.weight': torch.Size([8, 1]),\n",
              " 't.2.0.bias': torch.Size([8]),\n",
              " 't.2.2.weight': torch.Size([8, 8]),\n",
              " 't.2.2.bias': torch.Size([8]),\n",
              " 't.2.4.weight': torch.Size([1, 8]),\n",
              " 't.2.4.bias': torch.Size([1]),\n",
              " 't.3.0.weight': torch.Size([8, 1]),\n",
              " 't.3.0.bias': torch.Size([8]),\n",
              " 't.3.2.weight': torch.Size([8, 8]),\n",
              " 't.3.2.bias': torch.Size([8]),\n",
              " 't.3.4.weight': torch.Size([1, 8]),\n",
              " 't.3.4.bias': torch.Size([1]),\n",
              " 't.4.0.weight': torch.Size([8, 1]),\n",
              " 't.4.0.bias': torch.Size([8]),\n",
              " 't.4.2.weight': torch.Size([8, 8]),\n",
              " 't.4.2.bias': torch.Size([8]),\n",
              " 't.4.4.weight': torch.Size([1, 8]),\n",
              " 't.4.4.bias': torch.Size([1]),\n",
              " 't.5.0.weight': torch.Size([8, 1]),\n",
              " 't.5.0.bias': torch.Size([8]),\n",
              " 't.5.2.weight': torch.Size([8, 8]),\n",
              " 't.5.2.bias': torch.Size([8]),\n",
              " 't.5.4.weight': torch.Size([1, 8]),\n",
              " 't.5.4.bias': torch.Size([1]),\n",
              " 't.6.0.weight': torch.Size([8, 1]),\n",
              " 't.6.0.bias': torch.Size([8]),\n",
              " 't.6.2.weight': torch.Size([8, 8]),\n",
              " 't.6.2.bias': torch.Size([8]),\n",
              " 't.6.4.weight': torch.Size([1, 8]),\n",
              " 't.6.4.bias': torch.Size([1]),\n",
              " 't.7.0.weight': torch.Size([8, 1]),\n",
              " 't.7.0.bias': torch.Size([8]),\n",
              " 't.7.2.weight': torch.Size([8, 8]),\n",
              " 't.7.2.bias': torch.Size([8]),\n",
              " 't.7.4.weight': torch.Size([1, 8]),\n",
              " 't.7.4.bias': torch.Size([1]),\n",
              " 't.8.0.weight': torch.Size([8, 1]),\n",
              " 't.8.0.bias': torch.Size([8]),\n",
              " 't.8.2.weight': torch.Size([8, 8]),\n",
              " 't.8.2.bias': torch.Size([8]),\n",
              " 't.8.4.weight': torch.Size([1, 8]),\n",
              " 't.8.4.bias': torch.Size([1]),\n",
              " 't.9.0.weight': torch.Size([8, 1]),\n",
              " 't.9.0.bias': torch.Size([8]),\n",
              " 't.9.2.weight': torch.Size([8, 8]),\n",
              " 't.9.2.bias': torch.Size([8]),\n",
              " 't.9.4.weight': torch.Size([1, 8]),\n",
              " 't.9.4.bias': torch.Size([1]),\n",
              " 't.10.0.weight': torch.Size([8, 1]),\n",
              " 't.10.0.bias': torch.Size([8]),\n",
              " 't.10.2.weight': torch.Size([8, 8]),\n",
              " 't.10.2.bias': torch.Size([8]),\n",
              " 't.10.4.weight': torch.Size([1, 8]),\n",
              " 't.10.4.bias': torch.Size([1]),\n",
              " 't.11.0.weight': torch.Size([8, 1]),\n",
              " 't.11.0.bias': torch.Size([8]),\n",
              " 't.11.2.weight': torch.Size([8, 8]),\n",
              " 't.11.2.bias': torch.Size([8]),\n",
              " 't.11.4.weight': torch.Size([1, 8]),\n",
              " 't.11.4.bias': torch.Size([1]),\n",
              " 't.12.0.weight': torch.Size([8, 1]),\n",
              " 't.12.0.bias': torch.Size([8]),\n",
              " 't.12.2.weight': torch.Size([8, 8]),\n",
              " 't.12.2.bias': torch.Size([8]),\n",
              " 't.12.4.weight': torch.Size([1, 8]),\n",
              " 't.12.4.bias': torch.Size([1]),\n",
              " 't.13.0.weight': torch.Size([8, 1]),\n",
              " 't.13.0.bias': torch.Size([8]),\n",
              " 't.13.2.weight': torch.Size([8, 8]),\n",
              " 't.13.2.bias': torch.Size([8]),\n",
              " 't.13.4.weight': torch.Size([1, 8]),\n",
              " 't.13.4.bias': torch.Size([1]),\n",
              " 't.14.0.weight': torch.Size([8, 1]),\n",
              " 't.14.0.bias': torch.Size([8]),\n",
              " 't.14.2.weight': torch.Size([8, 8]),\n",
              " 't.14.2.bias': torch.Size([8]),\n",
              " 't.14.4.weight': torch.Size([1, 8]),\n",
              " 't.14.4.bias': torch.Size([1]),\n",
              " 't.15.0.weight': torch.Size([8, 1]),\n",
              " 't.15.0.bias': torch.Size([8]),\n",
              " 't.15.2.weight': torch.Size([8, 8]),\n",
              " 't.15.2.bias': torch.Size([8]),\n",
              " 't.15.4.weight': torch.Size([1, 8]),\n",
              " 't.15.4.bias': torch.Size([1]),\n",
              " 's.0.0.weight': torch.Size([8, 1]),\n",
              " 's.0.0.bias': torch.Size([8]),\n",
              " 's.0.2.weight': torch.Size([8, 8]),\n",
              " 's.0.2.bias': torch.Size([8]),\n",
              " 's.0.4.weight': torch.Size([1, 8]),\n",
              " 's.0.4.bias': torch.Size([1]),\n",
              " 's.1.0.weight': torch.Size([8, 1]),\n",
              " 's.1.0.bias': torch.Size([8]),\n",
              " 's.1.2.weight': torch.Size([8, 8]),\n",
              " 's.1.2.bias': torch.Size([8]),\n",
              " 's.1.4.weight': torch.Size([1, 8]),\n",
              " 's.1.4.bias': torch.Size([1]),\n",
              " 's.2.0.weight': torch.Size([8, 1]),\n",
              " 's.2.0.bias': torch.Size([8]),\n",
              " 's.2.2.weight': torch.Size([8, 8]),\n",
              " 's.2.2.bias': torch.Size([8]),\n",
              " 's.2.4.weight': torch.Size([1, 8]),\n",
              " 's.2.4.bias': torch.Size([1]),\n",
              " 's.3.0.weight': torch.Size([8, 1]),\n",
              " 's.3.0.bias': torch.Size([8]),\n",
              " 's.3.2.weight': torch.Size([8, 8]),\n",
              " 's.3.2.bias': torch.Size([8]),\n",
              " 's.3.4.weight': torch.Size([1, 8]),\n",
              " 's.3.4.bias': torch.Size([1]),\n",
              " 's.4.0.weight': torch.Size([8, 1]),\n",
              " 's.4.0.bias': torch.Size([8]),\n",
              " 's.4.2.weight': torch.Size([8, 8]),\n",
              " 's.4.2.bias': torch.Size([8]),\n",
              " 's.4.4.weight': torch.Size([1, 8]),\n",
              " 's.4.4.bias': torch.Size([1]),\n",
              " 's.5.0.weight': torch.Size([8, 1]),\n",
              " 's.5.0.bias': torch.Size([8]),\n",
              " 's.5.2.weight': torch.Size([8, 8]),\n",
              " 's.5.2.bias': torch.Size([8]),\n",
              " 's.5.4.weight': torch.Size([1, 8]),\n",
              " 's.5.4.bias': torch.Size([1]),\n",
              " 's.6.0.weight': torch.Size([8, 1]),\n",
              " 's.6.0.bias': torch.Size([8]),\n",
              " 's.6.2.weight': torch.Size([8, 8]),\n",
              " 's.6.2.bias': torch.Size([8]),\n",
              " 's.6.4.weight': torch.Size([1, 8]),\n",
              " 's.6.4.bias': torch.Size([1]),\n",
              " 's.7.0.weight': torch.Size([8, 1]),\n",
              " 's.7.0.bias': torch.Size([8]),\n",
              " 's.7.2.weight': torch.Size([8, 8]),\n",
              " 's.7.2.bias': torch.Size([8]),\n",
              " 's.7.4.weight': torch.Size([1, 8]),\n",
              " 's.7.4.bias': torch.Size([1]),\n",
              " 's.8.0.weight': torch.Size([8, 1]),\n",
              " 's.8.0.bias': torch.Size([8]),\n",
              " 's.8.2.weight': torch.Size([8, 8]),\n",
              " 's.8.2.bias': torch.Size([8]),\n",
              " 's.8.4.weight': torch.Size([1, 8]),\n",
              " 's.8.4.bias': torch.Size([1]),\n",
              " 's.9.0.weight': torch.Size([8, 1]),\n",
              " 's.9.0.bias': torch.Size([8]),\n",
              " 's.9.2.weight': torch.Size([8, 8]),\n",
              " 's.9.2.bias': torch.Size([8]),\n",
              " 's.9.4.weight': torch.Size([1, 8]),\n",
              " 's.9.4.bias': torch.Size([1]),\n",
              " 's.10.0.weight': torch.Size([8, 1]),\n",
              " 's.10.0.bias': torch.Size([8]),\n",
              " 's.10.2.weight': torch.Size([8, 8]),\n",
              " 's.10.2.bias': torch.Size([8]),\n",
              " 's.10.4.weight': torch.Size([1, 8]),\n",
              " 's.10.4.bias': torch.Size([1]),\n",
              " 's.11.0.weight': torch.Size([8, 1]),\n",
              " 's.11.0.bias': torch.Size([8]),\n",
              " 's.11.2.weight': torch.Size([8, 8]),\n",
              " 's.11.2.bias': torch.Size([8]),\n",
              " 's.11.4.weight': torch.Size([1, 8]),\n",
              " 's.11.4.bias': torch.Size([1]),\n",
              " 's.12.0.weight': torch.Size([8, 1]),\n",
              " 's.12.0.bias': torch.Size([8]),\n",
              " 's.12.2.weight': torch.Size([8, 8]),\n",
              " 's.12.2.bias': torch.Size([8]),\n",
              " 's.12.4.weight': torch.Size([1, 8]),\n",
              " 's.12.4.bias': torch.Size([1]),\n",
              " 's.13.0.weight': torch.Size([8, 1]),\n",
              " 's.13.0.bias': torch.Size([8]),\n",
              " 's.13.2.weight': torch.Size([8, 8]),\n",
              " 's.13.2.bias': torch.Size([8]),\n",
              " 's.13.4.weight': torch.Size([1, 8]),\n",
              " 's.13.4.bias': torch.Size([1]),\n",
              " 's.14.0.weight': torch.Size([8, 1]),\n",
              " 's.14.0.bias': torch.Size([8]),\n",
              " 's.14.2.weight': torch.Size([8, 8]),\n",
              " 's.14.2.bias': torch.Size([8]),\n",
              " 's.14.4.weight': torch.Size([1, 8]),\n",
              " 's.14.4.bias': torch.Size([1]),\n",
              " 's.15.0.weight': torch.Size([8, 1]),\n",
              " 's.15.0.bias': torch.Size([8]),\n",
              " 's.15.2.weight': torch.Size([8, 8]),\n",
              " 's.15.2.bias': torch.Size([8]),\n",
              " 's.15.4.weight': torch.Size([1, 8]),\n",
              " 's.15.4.bias': torch.Size([1]),\n",
              " 'v': torch.Size([2, 3])}"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Preview variational parameters:\n",
        "{n: p.shape for n, p in variational_params.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preview before optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([10240, 2, 3]), torch.Size([10240]))"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "samples, nlls = sampler(n_samples=10240)\n",
        "samples.shape, nlls.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[-0.0121,  0.0069,  0.0154],\n",
              "         [-0.0028,  0.0031,  0.0062]], grad_fn=<MeanBackward1>),\n",
              " tensor([[0.3379, 0.1095, 0.5542],\n",
              "         [0.1432, 0.1756, 0.6981]], grad_fn=<PowBackward0>),\n",
              " tensor([[ 0.3000, -0.2000, -0.4000,  0.0000, -0.0000, -0.0000],\n",
              "         [-0.2000,  0.1000,  0.2000, -0.0000,  0.0000,  0.0000],\n",
              "         [-0.4000,  0.2000,  0.6000, -0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000, -0.0000, -0.0000,  0.1000, -0.2000, -0.3000],\n",
              "         [-0.0000,  0.0000,  0.0000, -0.2000,  0.2000,  0.4000],\n",
              "         [-0.0000,  0.0000,  0.0000, -0.3000,  0.4000,  0.7000]],\n",
              "        grad_fn=<RoundBackward1>))"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Means, variances, covariance matrix:\n",
        "samples.mean(0), samples.std(0)**2, torch.cov(samples.flatten(start_dim=1).T).round(decimals=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.hist(samples[:,0].cpu().detach().numpy(), bins=30);\n",
        "plt.title(\"Dim=0 marginal distribution\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdEt2uU1g4qM"
      },
      "source": [
        "## Optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Gc6q2sg2JYeg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=0: loss= 7.66\n",
            "epoch=10: loss= 7.58\n",
            "epoch=20: loss= 7.51\n",
            "epoch=30: loss= 7.44\n",
            "epoch=40: loss= 7.39\n",
            "epoch=50: loss= 7.33\n",
            "epoch=60: loss= 7.29\n",
            "epoch=70: loss= 7.25\n",
            "epoch=80: loss= 7.22\n",
            "epoch=90: loss= 7.19\n",
            "epoch=500: loss= 6.97\n",
            "epoch=1000: loss= 6.97\n",
            "epoch=1500: loss= 6.98\n",
            "epoch=2000: loss= 6.97\n",
            "epoch=2500: loss= 6.97\n",
            "epoch=3000: loss= 6.97\n",
            "epoch=3500: loss= 6.97\n",
            "epoch=4000: loss= 6.97\n",
            "epoch=4500: loss= 6.97\n"
          ]
        }
      ],
      "source": [
        "optimized_parameters = variational_params.values()\n",
        "optimizer = torch.optim.Adam(optimized_parameters, lr=0.001) \n",
        "n_epochs = 5000\n",
        "n_posterior_samples = 1\n",
        "\n",
        "for e in range(n_epochs):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    samples, q_nlls = sampler(n_samples=n_posterior_samples)\n",
        "    p_nlls = calc_p_nll(samples)\n",
        "    KLD = p_nlls-q_nlls\n",
        "\n",
        "    loss_vi = KLD.mean()\n",
        "    loss_vi.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (e<100 and e%10==0) or e%500==0:\n",
        "        samples, q_nlls = sampler(n_samples=10240)  # let use  more samples to estimate reported KLD\n",
        "        p_nlls = calc_p_nll(samples)\n",
        "        KLD = p_nlls-q_nlls\n",
        "\n",
        "        print(f\"epoch={e}: loss={KLD.mean(): .2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preview after optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "um_HOFQK-lEz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 0.0032, -0.0032, -0.0032],\n",
              "         [ 0.0007, -0.0007, -0.0007]], grad_fn=<MeanBackward1>),\n",
              " tensor([[0.3308, 0.3308, 0.3308],\n",
              "         [0.3299, 0.3299, 0.3299]], grad_fn=<PowBackward0>),\n",
              " tensor([[ 0.3000, -0.3000, -0.3000,  0.0000, -0.0000, -0.0000],\n",
              "         [-0.3000,  0.3000,  0.3000, -0.0000,  0.0000,  0.0000],\n",
              "         [-0.3000,  0.3000,  0.3000, -0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000, -0.0000, -0.0000,  0.3000, -0.3000, -0.3000],\n",
              "         [-0.0000,  0.0000,  0.0000, -0.3000,  0.3000,  0.3000],\n",
              "         [-0.0000,  0.0000,  0.0000, -0.3000,  0.3000,  0.3000]],\n",
              "        grad_fn=<RoundBackward1>))"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "samples, nlls = sampler(n_samples=102400)\n",
        "\n",
        "# Means, variances, covariance matrix:\n",
        "samples.mean(0), samples.std(0)**2, torch.cov(samples.flatten(start_dim=1).T).round(decimals=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([0., 0., 0., 0., 0., 0.]),\n",
              " tensor([[1., 0., 0., 0., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 1.]]))"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# target:\n",
        "loc, cov "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "samples, nlls = sampler(n_samples=10240)\n",
        "plt.hist(samples[:, 0].cpu().detach().numpy(), bins=30);\n",
        "plt.title(\"Dim=0 marginal distribution\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "-C2DLYqynn54"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.3 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "5fa2277830e56cfe9810406d41944b45c11644b0708b697e0c2a22552bb91d92"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
