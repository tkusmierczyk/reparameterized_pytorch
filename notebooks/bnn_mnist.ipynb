{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning posteriors for BNN on MNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchmetrics tqdm pandas matplotlib\n",
    "!pip install \"numpy<2.0\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchmetrics.functional.classification import multiclass_calibration_error\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "import tqdm\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Failed to import NormFlows: No module named 'normflows'\n",
      "WARNING:root:Failed to import NormFlows: No module named 'normflows'\n"
     ]
    }
   ],
   "source": [
    "import reparameterized\n",
    "from reparameterized import sampling\n",
    "\n",
    "from reparameterized.likelihoods import (\n",
    "    categorical_posterior_probs as posterior_predictions,\n",
    ")\n",
    "from reparameterized.likelihoods import categorical_log_prob\n",
    "from reparameterized.bnn_wrapper import elbo_mc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"ipykernel\" in sys.argv[0]:\n",
    "    sys.argv = [\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--wandb'], dest='wandb', nargs=0, const=True, default=False, type=None, choices=None, required=False, help=None, metavar=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Reparameterized: BNN+MNIST\")\n",
    "\n",
    "parser.add_argument(\"--name\", type=str, default=None)\n",
    "\n",
    "parser.add_argument(\"--dataset\", type=str, default=\"mnist\", choices=(\"mnist\"))\n",
    "parser.add_argument(\"--batch_size\", type=int, default=1024)\n",
    "\n",
    "parser.add_argument(\"--optimizer\", type=str, default=\"Adam\")\n",
    "parser.add_argument(\"--lr\", type=float, default=1e-3)\n",
    "parser.add_argument(\"--n_posterior_samples\", type=int, default=17)\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=100)\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--posterior_model_architecture\",\n",
    "    type=str,\n",
    "    default=\"svd_rnvp_small_rezero\",\n",
    "    choices=(\n",
    "        \"rnvp_rezero\",\n",
    "        \"rnvp\",\n",
    "        \"rnvp_rezero_small\",\n",
    "        \"rnvp_small\",\n",
    "        \"factorized_gaussian\",\n",
    "        \"factorized_gaussian_rezero\",\n",
    "        \"gaussian_tril\",\n",
    "        \"gaussian_tril_rezero\",\n",
    "        \"gaussian_full\",\n",
    "        \"gaussian_full_rezero\",\n",
    "        \"svd_rnvp_small_rezero\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--distributional_parameters\", type=str, nargs=\"+\", default=[\"last_layer.weight\"]\n",
    ")\n",
    "\n",
    "parser.add_argument(\"--seed\", type=int, default=1863)\n",
    "parser.add_argument(\"--wandb\", default=False, action=\"store_true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = parser.parse_args()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.name is None:\n",
    "    distributional_parameters_str = \"_\".join(cfg.distributional_parameters)\n",
    "    cfg.name = f\"{cfg.dataset}_{cfg.posterior_model_architecture}_seed{cfg.seed}_N{cfg.n_posterior_samples}_E{cfg.n_epochs}_lr{cfg.lr}_P{distributional_parameters_str}_{cfg.optimizer}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wandb_log(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "\n",
    "if cfg.wandb:\n",
    "    import wandb\n",
    "\n",
    "    wandb.init(project=\"Reparameterized: BNN+MNIST\", config=cfg.__dict__, name=cfg.name)\n",
    "\n",
    "    def wandb_log(*args, **kwargs):\n",
    "        wandb.log(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfg = Namespace(name='mnist_svd_rnvp_small_rezero_seed1863_N17_E100_lr0.001_Plast_layer.weight_Adam', dataset='mnist', batch_size=1024, optimizer='Adam', lr=0.001, n_posterior_samples=17, n_epochs=100, posterior_model_architecture='svd_rnvp_small_rezero', distributional_parameters=['last_layer.weight'], seed=1863, wandb=False)\n"
     ]
    }
   ],
   "source": [
    "print(f\"cfg = {cfg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_dataloaders(batch_size=128):\n",
    "    mnist_train_dataset = torchvision.datasets.MNIST(\n",
    "        root=\"data\",\n",
    "        train=True,\n",
    "        transform=transforms.ToTensor(),\n",
    "        download=True,\n",
    "    )\n",
    "\n",
    "    mnist_test_dataset = torchvision.datasets.MNIST(\n",
    "        root=\"data\",\n",
    "        train=False,\n",
    "        transform=transforms.ToTensor(),\n",
    "    )\n",
    "\n",
    "    mnist_ood_dataset = torchvision.datasets.FashionMNIST(\n",
    "        root=\"data\",\n",
    "        train=False,\n",
    "        transform=transforms.ToTensor(),\n",
    "        download=True,\n",
    "    )\n",
    "\n",
    "    dataloader_train = DataLoader(\n",
    "        mnist_train_dataset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "    dataloader_test = DataLoader(\n",
    "        mnist_test_dataset, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    dataloader_ood = DataLoader(mnist_ood_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return dataloader_train, dataloader_test, dataloader_ood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNNMnist(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim=784,\n",
    "        out_dim=10,\n",
    "        hid_dim=128,\n",
    "        num_layers=2,\n",
    "        device=torch.device(\"cuda\"),\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.common_layers = nn.Sequential(\n",
    "            nn.Linear(self.in_dim, self.hid_dim),\n",
    "            *[\n",
    "                nn.Sequential(nn.Linear(self.hid_dim, self.hid_dim), nn.ELU())\n",
    "                for _ in range(self.num_layers)\n",
    "            ],\n",
    "        ).to(self.device)\n",
    "\n",
    "        self.last_layer = nn.Linear(self.hid_dim, self.out_dim).to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.common_layers(x)\n",
    "        x = self.last_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.dataset == \"mnist\":\n",
    "    train_dataloader, test_dataloader, _ = get_mnist_dataloaders(\n",
    "        batch_size=cfg.batch_size\n",
    "    )\n",
    "    bnn = BNNMnist(in_dim=784, out_dim=10, hid_dim=128, num_layers=2, device=device)\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Dataset={cfg.dataset} not supported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priors and Posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters:\n",
      " - common_layers.0.weight: torch.Size([128, 784]) (grad=True) (distribution=False)\n",
      " - common_layers.0.bias: torch.Size([128]) (grad=True) (distribution=False)\n",
      " - common_layers.1.0.weight: torch.Size([128, 128]) (grad=True) (distribution=False)\n",
      " - common_layers.1.0.bias: torch.Size([128]) (grad=True) (distribution=False)\n",
      " - common_layers.2.0.weight: torch.Size([128, 128]) (grad=True) (distribution=False)\n",
      " - common_layers.2.0.bias: torch.Size([128]) (grad=True) (distribution=False)\n",
      " - last_layer.weight: torch.Size([10, 128]) (grad=True) (distribution=True)\n",
      " - last_layer.bias: torch.Size([10]) (grad=True) (distribution=False)\n"
     ]
    }
   ],
   "source": [
    "pointwise_params = {}\n",
    "distributional_params = {}\n",
    "\n",
    "print(\"Model parameters:\")\n",
    "for n, p in bnn.named_parameters():\n",
    "\n",
    "    distributional = any(\n",
    "        (param_selector in n) for param_selector in cfg.distributional_parameters\n",
    "    )\n",
    "\n",
    "    print(f\" - {n}: {p.shape} (grad={p.requires_grad}) (distribution={distributional})\")\n",
    "\n",
    "    if distributional:\n",
    "        distributional_params[n] = p\n",
    "    else:\n",
    "        pointwise_params[n] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gaussian_basic_prior(p):\n",
    "    p = p.flatten()\n",
    "    return torch.distributions.MultivariateNormal(\n",
    "        loc=torch.zeros_like(p), covariance_matrix=torch.diag(torch.ones_like(p))\n",
    "    )\n",
    "\n",
    "\n",
    "priors = {n: create_gaussian_basic_prior(p) for n, p in distributional_params.items()}\n",
    "\n",
    "\n",
    "def log_priors(samples):\n",
    "    return sum(\n",
    "        priors[n].log_prob(p.flatten()) for n, p in samples.items()\n",
    "    )  # sum over all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(cfg.seed)\n",
    "torch.cuda.manual_seed(cfg.seed)\n",
    "torch.cuda.manual_seed_all(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior=svd_rnvp_small_rezero:\n",
      " - target_params = ['last_layer.weight']\n",
      " - sampler = <function parameter_samplers_to_joint_sampler.<locals>.single_sampler at 0x13802c9a0>\n",
      " - variational_params = ['last_layer.weight.alpha', 'last_layer.weight.beta', 'last_layer.weight.t.0.0.weight', 'last_layer.weight.t.0.0.bias', 'last_layer.weight.t.0.2.weight', 'last_layer.weight.t.0.2.bias', 'last_layer.weight.t.0.4.weight', 'last_layer.weight.t.0.4.bias', 'last_layer.weight.t.1.0.weight', 'last_layer.weight.t.1.0.bias', 'last_layer.weight.t.1.2.weight', 'last_layer.weight.t.1.2.bias', 'last_layer.weight.t.1.4.weight', 'last_layer.weight.t.1.4.bias', 'last_layer.weight.t.2.0.weight', 'last_layer.weight.t.2.0.bias', 'last_layer.weight.t.2.2.weight', 'last_layer.weight.t.2.2.bias', 'last_layer.weight.t.2.4.weight', 'last_layer.weight.t.2.4.bias', 'last_layer.weight.t.3.0.weight', 'last_layer.weight.t.3.0.bias', 'last_layer.weight.t.3.2.weight', 'last_layer.weight.t.3.2.bias', 'last_layer.weight.t.3.4.weight', 'last_layer.weight.t.3.4.bias', 'last_layer.weight.t.4.0.weight', 'last_layer.weight.t.4.0.bias', 'last_layer.weight.t.4.2.weight', 'last_layer.weight.t.4.2.bias', 'last_layer.weight.t.4.4.weight', 'last_layer.weight.t.4.4.bias', 'last_layer.weight.t.5.0.weight', 'last_layer.weight.t.5.0.bias', 'last_layer.weight.t.5.2.weight', 'last_layer.weight.t.5.2.bias', 'last_layer.weight.t.5.4.weight', 'last_layer.weight.t.5.4.bias', 'last_layer.weight.t.6.0.weight', 'last_layer.weight.t.6.0.bias', 'last_layer.weight.t.6.2.weight', 'last_layer.weight.t.6.2.bias', 'last_layer.weight.t.6.4.weight', 'last_layer.weight.t.6.4.bias', 'last_layer.weight.t.7.0.weight', 'last_layer.weight.t.7.0.bias', 'last_layer.weight.t.7.2.weight', 'last_layer.weight.t.7.2.bias', 'last_layer.weight.t.7.4.weight', 'last_layer.weight.t.7.4.bias', 'last_layer.weight.s.0.0.weight', 'last_layer.weight.s.0.0.bias', 'last_layer.weight.s.0.2.weight', 'last_layer.weight.s.0.2.bias', 'last_layer.weight.s.0.4.weight', 'last_layer.weight.s.0.4.bias', 'last_layer.weight.s.1.0.weight', 'last_layer.weight.s.1.0.bias', 'last_layer.weight.s.1.2.weight', 'last_layer.weight.s.1.2.bias', 'last_layer.weight.s.1.4.weight', 'last_layer.weight.s.1.4.bias', 'last_layer.weight.s.2.0.weight', 'last_layer.weight.s.2.0.bias', 'last_layer.weight.s.2.2.weight', 'last_layer.weight.s.2.2.bias', 'last_layer.weight.s.2.4.weight', 'last_layer.weight.s.2.4.bias', 'last_layer.weight.s.3.0.weight', 'last_layer.weight.s.3.0.bias', 'last_layer.weight.s.3.2.weight', 'last_layer.weight.s.3.2.bias', 'last_layer.weight.s.3.4.weight', 'last_layer.weight.s.3.4.bias', 'last_layer.weight.s.4.0.weight', 'last_layer.weight.s.4.0.bias', 'last_layer.weight.s.4.2.weight', 'last_layer.weight.s.4.2.bias', 'last_layer.weight.s.4.4.weight', 'last_layer.weight.s.4.4.bias', 'last_layer.weight.s.5.0.weight', 'last_layer.weight.s.5.0.bias', 'last_layer.weight.s.5.2.weight', 'last_layer.weight.s.5.2.bias', 'last_layer.weight.s.5.4.weight', 'last_layer.weight.s.5.4.bias', 'last_layer.weight.s.6.0.weight', 'last_layer.weight.s.6.0.bias', 'last_layer.weight.s.6.2.weight', 'last_layer.weight.s.6.2.bias', 'last_layer.weight.s.6.4.weight', 'last_layer.weight.s.6.4.bias', 'last_layer.weight.s.7.0.weight', 'last_layer.weight.s.7.0.bias', 'last_layer.weight.s.7.2.weight', 'last_layer.weight.s.7.2.bias', 'last_layer.weight.s.7.4.weight', 'last_layer.weight.s.7.4.bias']\n",
      " - aux_objs = ['flow', 'u', 'vh', 's']\n"
     ]
    }
   ],
   "source": [
    "# Each parameter gets its own sampler\n",
    "parameter2sampler, variational_params, aux_objs = sampling.create_independent_samplers(\n",
    "    distributional_params, cfg.posterior_model_architecture\n",
    ")\n",
    "sampler = reparameterized.parameter_samplers_to_joint_sampler(parameter2sampler)\n",
    "\n",
    "# All parameters are put together and use a joint sampler\n",
    "# sampler, variational_params, aux_objs = sampling.create_joint_sampler(\n",
    "#     distributional_params, cfg.posterior_model_architecture\n",
    "# )\n",
    "\n",
    "print(f\"Posterior={cfg.posterior_model_architecture}:\")\n",
    "print(f\" - target_params = {list(distributional_params.keys())}\")\n",
    "print(f\" - sampler = {sampler}\")\n",
    "print(f\" - variational_params = {list(variational_params.keys())}\")\n",
    "print(f\" - aux_objs = {list(aux_objs.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_posterior(bnn, samples, dataloader, name_preffix=\"\", device=device):\n",
    "    metrics = dict()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_probabilities = []\n",
    "\n",
    "    for step_no, (x, y) in enumerate(dataloader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        probs = posterior_predictions(bnn, x, samples=samples)\n",
    "        probs = torch.mean(probs, dim=0)\n",
    "        class_predictions = torch.argmax(probs, dim=-1)\n",
    "\n",
    "        all_targets.append(y)\n",
    "        all_predictions.append(class_predictions)\n",
    "        all_probabilities.append(probs)\n",
    "\n",
    "    all_targets = torch.cat(all_targets)\n",
    "    all_predictions = torch.cat(all_predictions)\n",
    "    all_probabilities = torch.cat(all_probabilities)\n",
    "\n",
    "    accuracy = torch.sum(all_predictions == all_targets) / len(all_targets)\n",
    "\n",
    "    ece_l1 = multiclass_calibration_error(\n",
    "        preds=all_probabilities,\n",
    "        target=all_targets,\n",
    "        num_classes=10,\n",
    "        n_bins=15,\n",
    "        norm=\"l1\",\n",
    "    )\n",
    "    ece_l2 = multiclass_calibration_error(\n",
    "        preds=all_probabilities,\n",
    "        target=all_targets,\n",
    "        num_classes=10,\n",
    "        n_bins=15,\n",
    "        norm=\"l2\",\n",
    "    )\n",
    "    ece_max = multiclass_calibration_error(\n",
    "        preds=all_probabilities,\n",
    "        target=all_targets,\n",
    "        num_classes=10,\n",
    "        n_bins=15,\n",
    "        norm=\"max\",\n",
    "    )\n",
    "\n",
    "    metrics[f\"{name_preffix}eval_accuracy\"] = accuracy\n",
    "    metrics[f\"{name_preffix}eval_ece_l1\"] = ece_l1\n",
    "    metrics[f\"{name_preffix}eval_ece_l2\"] = ece_l2\n",
    "    metrics[f\"{name_preffix}eval_ece_max\"] = ece_max\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate before training\n",
      "[start] metrics=eval_accuracy=0.08 eval_ece_l1=0.02 eval_ece_l2=0.02 eval_ece_max=0.02\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate before training\")\n",
    "\n",
    "samples, q_nlls = sampler(n_samples=111)\n",
    "assert not q_nlls.isnan().any(), q_nlls\n",
    "\n",
    "metrics = eval_posterior(bnn, samples, test_dataloader, device=device)\n",
    "metrics_str = \" \".join([f\"{k}={v:.2f}\" for k, v in metrics.items()])\n",
    "print(f\"[start] metrics={metrics_str}\")\n",
    "wandb_log(metrics, step=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(cfg.seed)\n",
    "torch.cuda.manual_seed(cfg.seed)\n",
    "torch.cuda.manual_seed_all(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#variational params = 471856\n"
     ]
    }
   ],
   "source": [
    "total_variational_params = sum(p.numel() for p in variational_params.values())\n",
    "print(f\"#variational params = {total_variational_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_parameters = list(variational_params.values()) + list(\n",
    "    pointwise_params.values()\n",
    ")\n",
    "optimizer = getattr(torch.optim, cfg.optimizer)(optimized_parameters, lr=cfg.lr)\n",
    "\n",
    "omega = 1.0\n",
    "beta = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:13,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 16s][epoch=0] train: loss=114403.42 log_lik=-113206.98 KLD=1196.44  / test metrics: eval_accuracy=0.843 eval_ece_l1=0.046 eval_ece_l2=0.059 eval_ece_max=0.140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:13,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 32s][epoch=1] train: loss=25516.52 log_lik=-23205.41 KLD=2311.11  / test metrics: eval_accuracy=0.920 eval_ece_l1=0.026 eval_ece_l2=0.034 eval_ece_max=0.080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:16,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 52s][epoch=2] train: loss=19215.60 log_lik=-16992.15 KLD=2223.45  / test metrics: eval_accuracy=0.927 eval_ece_l1=0.018 eval_ece_l2=0.026 eval_ece_max=0.262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:16,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 73s][epoch=3] train: loss=15830.50 log_lik=-13666.61 KLD=2163.89  / test metrics: eval_accuracy=0.941 eval_ece_l1=0.016 eval_ece_l2=0.024 eval_ece_max=0.126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:17,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 95s][epoch=4] train: loss=13075.53 log_lik=-11032.54 KLD=2042.99  / test metrics: eval_accuracy=0.953 eval_ece_l1=0.015 eval_ece_l2=0.026 eval_ece_max=0.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:15,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 114s][epoch=5] train: loss=11140.46 log_lik=-9165.95 KLD=1974.50  / test metrics: eval_accuracy=0.956 eval_ece_l1=0.010 eval_ece_l2=0.021 eval_ece_max=0.490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:15,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 133s][epoch=6] train: loss=10066.40 log_lik=-8174.38 KLD=1892.02  / test metrics: eval_accuracy=0.961 eval_ece_l1=0.004 eval_ece_l2=0.016 eval_ece_max=0.731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:15,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 152s][epoch=7] train: loss=9223.14 log_lik=-7400.09 KLD=1823.05  / test metrics: eval_accuracy=0.964 eval_ece_l1=0.007 eval_ece_l2=0.017 eval_ece_max=0.167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:16,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 172s][epoch=8] train: loss=8400.91 log_lik=-6632.11 KLD=1768.80  / test metrics: eval_accuracy=0.966 eval_ece_l1=0.011 eval_ece_l2=0.022 eval_ece_max=0.257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:15,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 191s][epoch=9] train: loss=7658.09 log_lik=-5915.29 KLD=1742.80  / test metrics: eval_accuracy=0.969 eval_ece_l1=0.003 eval_ece_l2=0.011 eval_ece_max=0.243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:16,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 211s][epoch=10] train: loss=7188.75 log_lik=-5468.07 KLD=1720.68  / test metrics: eval_accuracy=0.969 eval_ece_l1=0.004 eval_ece_l2=0.010 eval_ece_max=0.059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:15,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 230s][epoch=11] train: loss=6538.89 log_lik=-4837.72 KLD=1701.17  / test metrics: eval_accuracy=0.969 eval_ece_l1=0.003 eval_ece_l2=0.012 eval_ece_max=0.427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:15,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 248s][epoch=12] train: loss=6413.94 log_lik=-4741.52 KLD=1672.42  / test metrics: eval_accuracy=0.969 eval_ece_l1=0.005 eval_ece_l2=0.019 eval_ece_max=0.311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:15,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 267s][epoch=13] train: loss=5893.69 log_lik=-4229.39 KLD=1664.30  / test metrics: eval_accuracy=0.972 eval_ece_l1=0.004 eval_ece_l2=0.016 eval_ece_max=0.242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:15,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 287s][epoch=14] train: loss=5628.82 log_lik=-3989.40 KLD=1639.42  / test metrics: eval_accuracy=0.973 eval_ece_l1=0.003 eval_ece_l2=0.019 eval_ece_max=0.697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:15,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 306s][epoch=15] train: loss=5185.56 log_lik=-3531.89 KLD=1653.67  / test metrics: eval_accuracy=0.973 eval_ece_l1=0.003 eval_ece_l2=0.011 eval_ece_max=0.096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:14,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 325s][epoch=16] train: loss=4995.27 log_lik=-3348.72 KLD=1646.55  / test metrics: eval_accuracy=0.972 eval_ece_l1=0.003 eval_ece_l2=0.011 eval_ece_max=0.289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:15,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 344s][epoch=17] train: loss=4889.33 log_lik=-3264.36 KLD=1624.98  / test metrics: eval_accuracy=0.974 eval_ece_l1=0.004 eval_ece_l2=0.014 eval_ece_max=0.312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:15,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 363s][epoch=18] train: loss=4617.02 log_lik=-3014.94 KLD=1602.08  / test metrics: eval_accuracy=0.975 eval_ece_l1=0.007 eval_ece_l2=0.017 eval_ece_max=0.679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:16,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 383s][epoch=19] train: loss=4315.06 log_lik=-2695.53 KLD=1619.53  / test metrics: eval_accuracy=0.975 eval_ece_l1=0.005 eval_ece_l2=0.019 eval_ece_max=0.345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:15,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 402s][epoch=20] train: loss=4051.30 log_lik=-2442.46 KLD=1608.84  / test metrics: eval_accuracy=0.974 eval_ece_l1=0.009 eval_ece_l2=0.024 eval_ece_max=0.288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:15,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 420s][epoch=21] train: loss=3826.44 log_lik=-2209.97 KLD=1616.46  / test metrics: eval_accuracy=0.976 eval_ece_l1=0.004 eval_ece_l2=0.012 eval_ece_max=0.295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:16,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 440s][epoch=22] train: loss=3698.02 log_lik=-2082.89 KLD=1615.14  / test metrics: eval_accuracy=0.974 eval_ece_l1=0.008 eval_ece_l2=0.024 eval_ece_max=0.311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:15,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 459s][epoch=23] train: loss=3544.90 log_lik=-1948.49 KLD=1596.41  / test metrics: eval_accuracy=0.976 eval_ece_l1=0.009 eval_ece_l2=0.028 eval_ece_max=0.703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:15,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 479s][epoch=24] train: loss=3496.47 log_lik=-1909.08 KLD=1587.38  / test metrics: eval_accuracy=0.975 eval_ece_l1=0.008 eval_ece_l2=0.023 eval_ece_max=0.310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:18,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 502s][epoch=25] train: loss=3346.60 log_lik=-1764.56 KLD=1582.04  / test metrics: eval_accuracy=0.977 eval_ece_l1=0.008 eval_ece_l2=0.023 eval_ece_max=0.249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:16,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 521s][epoch=26] train: loss=3104.50 log_lik=-1521.97 KLD=1582.54  / test metrics: eval_accuracy=0.977 eval_ece_l1=0.008 eval_ece_l2=0.023 eval_ece_max=0.295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:15,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 541s][epoch=27] train: loss=3037.86 log_lik=-1452.44 KLD=1585.42  / test metrics: eval_accuracy=0.977 eval_ece_l1=0.010 eval_ece_l2=0.027 eval_ece_max=0.311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:15,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 560s][epoch=28] train: loss=2898.02 log_lik=-1317.72 KLD=1580.30  / test metrics: eval_accuracy=0.975 eval_ece_l1=0.010 eval_ece_l2=0.024 eval_ece_max=0.312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:17,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 581s][epoch=29] train: loss=2710.22 log_lik=-1121.02 KLD=1589.19  / test metrics: eval_accuracy=0.975 eval_ece_l1=0.010 eval_ece_l2=0.025 eval_ece_max=0.680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:19,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 605s][epoch=30] train: loss=2785.43 log_lik=-1223.95 KLD=1561.48  / test metrics: eval_accuracy=0.977 eval_ece_l1=0.010 eval_ece_l2=0.027 eval_ece_max=0.317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:17,  3.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 626s][epoch=31] train: loss=2713.29 log_lik=-1159.94 KLD=1553.35  / test metrics: eval_accuracy=0.978 eval_ece_l1=0.009 eval_ece_l2=0.026 eval_ece_max=0.435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:15,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 645s][epoch=32] train: loss=2514.11 log_lik=-958.11 KLD=1555.99  / test metrics: eval_accuracy=0.977 eval_ece_l1=0.010 eval_ece_l2=0.030 eval_ece_max=0.691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:16,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 665s][epoch=33] train: loss=2474.59 log_lik=-925.63 KLD=1548.96  / test metrics: eval_accuracy=0.977 eval_ece_l1=0.011 eval_ece_l2=0.030 eval_ece_max=0.275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:16,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 684s][epoch=34] train: loss=2402.82 log_lik=-851.34 KLD=1551.48  / test metrics: eval_accuracy=0.977 eval_ece_l1=0.010 eval_ece_l2=0.025 eval_ece_max=0.371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:15,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 704s][epoch=35] train: loss=2303.36 log_lik=-759.02 KLD=1544.34  / test metrics: eval_accuracy=0.975 eval_ece_l1=0.014 eval_ece_l2=0.035 eval_ece_max=0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:16,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 724s][epoch=36] train: loss=2268.20 log_lik=-726.59 KLD=1541.60  / test metrics: eval_accuracy=0.974 eval_ece_l1=0.013 eval_ece_l2=0.037 eval_ece_max=0.686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:16,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 745s][epoch=37] train: loss=2181.51 log_lik=-651.08 KLD=1530.42  / test metrics: eval_accuracy=0.979 eval_ece_l1=0.011 eval_ece_l2=0.030 eval_ece_max=0.688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:17,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 766s][epoch=38] train: loss=2218.16 log_lik=-695.14 KLD=1523.01  / test metrics: eval_accuracy=0.978 eval_ece_l1=0.011 eval_ece_l2=0.026 eval_ece_max=0.383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:16,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 786s][epoch=39] train: loss=2053.38 log_lik=-527.98 KLD=1525.40  / test metrics: eval_accuracy=0.979 eval_ece_l1=0.010 eval_ece_l2=0.025 eval_ece_max=0.213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:16,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 805s][epoch=40] train: loss=1975.15 log_lik=-459.21 KLD=1515.94  / test metrics: eval_accuracy=0.977 eval_ece_l1=0.012 eval_ece_l2=0.032 eval_ece_max=0.302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:15,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 825s][epoch=41] train: loss=1923.16 log_lik=-414.81 KLD=1508.35  / test metrics: eval_accuracy=0.978 eval_ece_l1=0.012 eval_ece_l2=0.035 eval_ece_max=0.376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:16,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 845s][epoch=42] train: loss=1859.57 log_lik=-349.07 KLD=1510.50  / test metrics: eval_accuracy=0.979 eval_ece_l1=0.012 eval_ece_l2=0.034 eval_ece_max=0.325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:17,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 866s][epoch=43] train: loss=1893.50 log_lik=-392.41 KLD=1501.09  / test metrics: eval_accuracy=0.977 eval_ece_l1=0.012 eval_ece_l2=0.036 eval_ece_max=0.355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:16,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 886s][epoch=44] train: loss=1783.03 log_lik=-291.64 KLD=1491.39  / test metrics: eval_accuracy=0.978 eval_ece_l1=0.012 eval_ece_l2=0.036 eval_ece_max=0.410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:15,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 906s][epoch=45] train: loss=1790.20 log_lik=-299.31 KLD=1490.89  / test metrics: eval_accuracy=0.978 eval_ece_l1=0.012 eval_ece_l2=0.030 eval_ece_max=0.322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:04,  3.14it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     21\u001b[39m log_lik, KLD = elbo_res[\u001b[33m\"\u001b[39m\u001b[33mll\u001b[39m\u001b[33m\"\u001b[39m], elbo_res[\u001b[33m\"\u001b[39m\u001b[33mkl\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     22\u001b[39m loss_vi = -(omega * log_lik - beta * KLD)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mloss_vi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m loss_vi_k.append(loss_vi.detach().cpu().item())\n\u001b[32m     26\u001b[39m KLD_k.append(KLD.detach().cpu().item())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prj/reparametrized_pytorch/.env/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    513\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    514\u001b[39m         Tensor.backward,\n\u001b[32m    515\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    520\u001b[39m         inputs=inputs,\n\u001b[32m    521\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/prj/reparametrized_pytorch/.env/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    261\u001b[39m     retain_graph = create_graph\n\u001b[32m    263\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    264\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for epoch in range(cfg.n_epochs):\n",
    "\n",
    "    loss_vi_k = []\n",
    "    KLD_k = []\n",
    "    log_lik_k = []\n",
    "    for it, (x, y) in tqdm.tqdm(enumerate(train_dataloader)):\n",
    "        full2minibatch_ratio = len(train_dataloader.dataset) / len(x)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        elbo_res = elbo_mc(\n",
    "            bnn,\n",
    "            x,\n",
    "            y,\n",
    "            log_priors,\n",
    "            categorical_log_prob,\n",
    "            sampler,\n",
    "            cfg.n_posterior_samples,\n",
    "            full2minibatch_ratio,\n",
    "        )\n",
    "        log_lik, KLD = elbo_res[\"ll\"], elbo_res[\"kl\"]\n",
    "        loss_vi = -(omega * log_lik - beta * KLD)\n",
    "        loss_vi.backward()\n",
    "\n",
    "        loss_vi_k.append(loss_vi.detach().cpu().item())\n",
    "        KLD_k.append(KLD.detach().cpu().item())\n",
    "        log_lik_k.append(log_lik.detach().cpu().item())\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    # reporting\n",
    "    log_lik = np.mean(log_lik_k)\n",
    "    KLD = np.mean(KLD_k)\n",
    "    loss_vi = np.mean(loss_vi_k)\n",
    "\n",
    "    samples, q_nlls = sampler(n_samples=111)\n",
    "    assert not q_nlls.isnan().any(), q_nlls\n",
    "\n",
    "    metrics = eval_posterior(bnn, samples, test_dataloader, device=device)\n",
    "    metrics_str = \" \".join([f\"{k}={v:.3f}\" for k, v in metrics.items()])\n",
    "    wandb_log(metrics, step=epoch)\n",
    "\n",
    "    res_str = f\"train: loss={loss_vi:.2f} log_lik={log_lik:.2f} KLD={KLD:.2f}\"\n",
    "    print(\n",
    "        f\"[{time.time()-start_time:.0f}s][epoch={epoch}] {res_str}  / test metrics: {metrics_str}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
